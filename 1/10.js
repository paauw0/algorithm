/**
  * @description: K最近邻算法（k-nearest neighbours，KNN）
  */

// 要计算两点的距离，可使用毕达哥拉斯公式。

/**
  * 公式
  * 这个公式包含5个而不是2个数字。
  * 这个距离公式很灵活，即便涉及很多个数字，依然可以使用它来计算距离。
  * 你可能会问，涉及5个数字时，距离意味着什么呢？这种距离指出了两组数字之间的相似程度。
  */
let a = [3, 4, 4, 1, 4]
let b = [2, 5, 1, 3, 1]
const result = Math.sqrt(
  Math.pow(a[0] - b[0], 2) +
  Math.pow(a[1] - b[1], 2) +
  Math.pow(a[2] - b[2], 2) +
  Math.pow(a[3] - b[3], 2) +
  Math.pow(a[4] - b[4], 2)
)

console.log(result)

// 本书不讨论余弦相似度，但如果你要使用KNN，就一定要研究研究它！

/**
  * 回归
  * 假设你要预测Priyanka会给电影Pitch Perfect打多少分。Justin、JC、Joey、Lance和Chris都给它打了多少分呢？
      Justin: 5
      JC: 4
      Joey: 4
      Lance: 5
      Chris: 3
  * 你求这些人打的分的平均值，结果为4.2。
  * 这就是回归（regression）。

  * 你将使用KNN来做两项基本工作——分类和回归：
      分类就是编组；
      回归就是预测结果（如一个数字）。
  */

/**
  * 回归很有用。
  * 假设你在伯克利开个小小的面包店，每天都做新鲜面包，需要根据如下一组特征预测当天该烤多少条面包：
      天气指数1～5（1表示天气很糟，5表示天气非常好）
      是不是周末或节假日（周末或节假日为1，否则为0）；
      有没有活动（1表示有，0表示没有）。
  * 你还有一些历史数据，记录了在各种不同的日子里售出的面包数量。
      A.(5, 1, 0) = 300
      B.(3, 1, 1) = 225
      C.(1, 1, 0) = 75
      D.(4, 0, 1) = 200
      E.(4, 0, 0) = 150
      F.(2, 0, 0) = 50
  * 今天是周末，天气不错。根据这些数据，预测你今天能售出多少条面包呢？
  * 我们来使用KNN算法，其中的K为4。
  * 首先，找出与今天最接近的4个邻居。
      (4, 1, 0) = ?
  * 距离如下，因此最近的邻居为A、B、D和E。
      A.1
      B.2
      C.9
      D.2
      E.1
      F.5
  * 将这些天售出的面包数平均，结果为218.75。这就是你今天要烤的面包数！
  */

/**
  * 使用KNN时，挑选合适的特征进行比较至关重要。
  * 所谓合适的特征，就是：
      与要推荐的电影紧密相关的特征；
      不偏不倚的特征（例如，如果只让用户给喜剧片打分，就无法判断他们是否喜欢动作片）
  * 在挑选合适的特征方面，没有放之四海皆准的法则，你必须考虑到各种需要考虑的因素。
  */

/**
 * 垃圾邮件过滤器使用一种简单算法——朴素贝叶斯分类器（Naive Bayes classifier）
 */